{
  "acceptance criteria": "The criteria that a component or system must satisfy in order to be accepted by a user, customer, or other authorized entity.",
  "acceptance test-driven development": "A collaboration-based test-first approach that defines acceptance tests in the stakeholders' domain language.",
  "acceptance testing": "A test level that focuses on determining whether to accept the system.",
  "actual result": "The behavior produced/observed when a component or system is tested.",
  "Agile software development": "A group of software development methodologies based on iterative incremental development, where requirements and solutions evolve through collaboration between self-organizing cross-functional teams.",
  "alpha testing": "A type of acceptance testing performed in the developer's test environment by roles outside the development organization.",
  "anomaly": "A condition that deviates from expectation.",
  "API testing": "Testing performed by submitting requests to the test object using its application programming interface.",
  "audit": "An independent examination of a work product or process performed by a third party to assess whether it complies with specifications, standards, contractual agreements, or other criteria.",
  "availability": "The degree to which a component or system is operational and accessible when required for use.",
  "behavior-driven development": "A collaborative approach to development in which the team is focusing on delivering expected behavior of a component or system for the customer, which forms the basis for testing.",
  "beta testing": "A type of acceptance testing performed at an external site to the developer's test environment by roles outside the development organization.",
  "black-box test technique": "A test technique based on an analysis of the specification of a component or system.",
  "black-box testing": "Testing based on an analysis of the specification of the component or system.",
  "boundary value": "A minimum or maximum value of an ordered equivalence partition.",
  "boundary value analysis": "A black-box test technique in which test cases are designed based on boundary values.",
  "branch": "A transfer of control between two consecutive nodes in the control flow graph of a test item.",
  "branch coverage": "The coverage of branches in a control flow graph.",
  "branch testing": "A white-box test technique in which the test conditions are branches.",
  "cause-effect diagram": "A graphical representation used to organize and display the interrelationships of various possible root causes of a problem. Possible causes of a real or potential defect or failure are organized in categories and subcategories in a horizontal tree-structure, with the (potential) defect or failure as the root node.",
  "checklist-based review": "A review technique guided by a list of questions or required attributes.",
  "checklist-based testing": "An experience-based test technique in which test cases are designed to exercise the items of a checklist.",
  "coding standard": "A standard that describes the characteristics of a design or a design description of data or program components.",
  "collaboration-based test approach": "An approach to testing that focuses on defect avoidance by collaborating among stakeholders.",
  "compatibility": "The degree to which a component or system can exchange information with other components or systems, and/or perform its required functions while sharing the same hardware or software environment.",
  "compliance": "Adherence of a work product to standards, conventions or regulations in laws and similar prescriptions.",
  "component": "A part of a system that can be tested in isolation.",
  "component integration testing": "The integration testing of components.",
  "component testing": "A test level that focuses on individual hardware or software components.",
  "configuration management": "A discipline applying technical and administrative direction and surveillance to identify and document the functional and physical characteristics of a configuration item, control changes to those characteristics, record and report change processing and implementation status, and verify that it complies with specified requirements.",
  "confirmation testing": "A type of change-related testing performed after fixing a defect to confirm that a failure caused by that defect does not reoccur.",
  "continuous integration": "An automated software development procedure that merges, integrates and tests all changes as soon as they are committed.",
  "continuous testing": "A test approach that involves testing early, testing often, testing throughout the software development lifecycle, and automating to obtain feedback on the business risks associated with a software release candidate as soon as possible.",
  "control flow": "The sequence in which operations are performed by a business process, component or system.",
  "cost of quality": "The total costs incurred on quality activities and issues and often split into prevention costs, appraisal costs, internal failure costs and external failure costs.",
  "coverage": "The degree to which specified coverage items are exercised by a test suite, expressed as a percentage.",
  "coverage criteria": "The criteria to define the coverage items required to reach a test objective.",
  "coverage item": "An attribute or combination of attributes derived from one or more test conditions by using a test technique.",
  "dashboard": "A representation of dynamic measurements of operational performance for some organization or activity, using metrics represented via metaphors such as visual dials, counters, and other devices resembling those on the dashboard of an automobile, so that the effects of events or activities can be easily understood and related to operational goals.",
  "debugging": "The process of finding, analyzing and removing the causes of failures in a component or system.",
  "decision table testing": "A black-box test technique in which test cases are designed to exercise the combinations of conditions and the resulting actions shown in a decision table.",
  "defect": "An imperfection or deficiency in a work product where it does not meet its requirements or specifications.",
  "defect density": "The number of defects per unit size of a work product.",
  "Defect Detection Percentage": "The number of defects found by a test level, divided by the number found by that test level and any other means afterwards.",
  "defect management": "The process of recognizing, recording, classifying, investigating, resolving and disposing of defects.",
  "defect report": "Documentation of the occurrence, nature, and status of a defect.",
  "driver": "A component or tool that temporarily replaces another component and controls or calls a test item in isolation.",
  "dynamic testing": "Testing that involves the execution of the test item.",
  "effectiveness": "The extent to which correct and complete goals are achieved.",
  "efficiency": "The degree to which resources are expended in relation to results achieved.",
  "entry criteria": "The set of conditions for officially starting a defined task.",
  "equivalence partition": "A subset of the value domain of a variable within a component or system in which all values are expected to be treated the same based on the specification.",
  "equivalence partitioning": "A black-box test technique in which test conditions are equivalence partitions exercised by one representative member of each partition.",
  "error": "A human action that produces an incorrect result.",
  "error guessing": "A test technique in which tests are derived on the basis of the tester's knowledge of past failures, or general knowledge of failure modes.",
  "exhaustive testing": "A test approach in which the test suite comprises all combinations of input values and preconditions.",
  "exit criteria": "The set of conditions for officially completing a defined task.",
  "expected result": "The observable predicted behavior of a test item under specified conditions based on its test basis.",
  "experience-based test technique": "A test technique based on the tester's experience, knowledge and intuition.",
  "exploratory testing": "An approach to testing in which the testers dynamically design and execute tests based on their knowledge, exploration of the test item and the results of previous tests.",
  "failed": "The status of a test result if the actual result does not match the expected result.",
  "failure": "An event in which a component or system does not perform a required function within specified limits.",
  "fault attack": "A test technique to evaluate a specific quality characteristic of a test object by attempting to trigger specific failures.",
  "feature-driven development": "An iterative and incremental software development process driven from a client-valued functionality (feature) perspective. Feature-driven development is mostly used in Agile software development.",
  "finding": "A result of an evaluation that identifies some important issue, problem, or opportunity.",
  "formal review": "A review that follows a defined process with a formally documented output.",
  "functional appropriateness": "The degree to which the functions facilitate the accomplishment of specified tasks and objectives.",
  "functional completeness": "The degree to which the set of functions covers all the specified tasks and user objectives.",
  "functional correctness": "The degree to which a component or system provides the correct results with the needed degree of precision.",
  "functional testing": "Testing performed to evaluate if a component or system satisfies functional requirements.",
  "heuristic": "A generally recognized rule of thumb that helps to achieve a goal.",
  "impact analysis": "The identification of all work products affected by a change, including an estimate of the resources needed to accomplish the change.",
  "incremental development model": "A type of software development lifecycle model in which the component or system is developed through a series of increments.",
  "independence of testing": "Separation of responsibilities, which encourages the accomplishment of objective testing.",
  "informal review": "A type of review that does not follow a defined process and has no formally documented output.",
  "inspection": "A type of formal review that uses defined team roles and measurement to identify defects in a work product, and improve the review process and the software development process.",
  "integration testing": "A test level that focuses on interactions between components or systems.",
  "integrity": "The degree to which a component or system allows only authorized access and modification to a component, a system or data.",
  "iterative development model": "A type of software development lifecycle model in which the component or system is developed through a series of repeated cycles.",
  "maintainability": "The degree to which a component or system can be modified by the intended maintainers.",
  "maintenance": "The process of modifying a component or system after delivery to correct defects, improve quality characteristics, or adapt to a changed environment.",
  "maintenance testing": "Testing the changes to an operational system or the impact of a changed environment to an operational system.",
  "maturity": "(1) The capability of an organization with respect to the effectiveness and efficiency of its processes and work practices. (2) The degree to which a component or system meets needs for reliability under normal operation.",
  "mean time to failure": "The average time from the start of operation to a failure for a component or system.",
  "measurement": "The process of assigning a number or category to an entity to describe an attribute of that entity.",
  "metric": "A measurement scale and the method used for measurement.",
  "moderator": "(1) The person responsible for running review meetings. (2) The person who performs a usability test session.",
  "N-switch coverage": "The coverage of sequences of N+1 transitions.",
  "negative testing": "A type of testing in which a component or system is used in a way that it is not intended.",
  "neuron coverage": "The coverage of activated neurons in the neural network for a set of tests.",
  "non-functional testing": "Testing performed to evaluate that a component or system complies with non-functional requirements.",
  "operational acceptance testing": "A type of acceptance testing performed to determine if operations and/or systems administration staff can accept a system.",
  "pair testing": "A test approach in which two team members simultaneously collaborate on testing a work product.",
  "passed": "The status of a test result if the actual result matches the expected result.",
  "path": "A sequence of consecutive edges in a directed graph.",
  "performance efficiency": "The degree to which a component or system uses time, resources and capacity when accomplishing its designated functions.",
  "planning poker": "A consensus-based estimation technique, mostly used to estimate effort or relative size of user stories in Agile software development. It is a variation of the Wideband Delphi method using a deck of cards with values representing the units in which the team estimates.",
  "portability": "The degree to which a component or system can be transferred from one hardware, software or other operational or usage environment to another.",
  "postcondition": "The expected state of a test item and its environment at the end of test case execution.",
  "precondition": "The required state of a test item and its environment prior to test case execution.",
  "priority": "The level of (business) importance assigned to an item, e.g., defect.",
  "product risk": "A risk that impacts the quality of a product.",
  "project risk": "A risk that impacts project success.",
  "quality": "The degree to which a work product satisfies stated and implied needs of its stakeholders.",
  "quality assurance": "Activities focused on providing confidence that quality requirements will be fulfilled.",
  "quality characteristic": "A category of quality attributes that bears on work product quality.",
  "quality control": "Activities designed to evaluate the quality of a component or system.",
  "quality risk": "A product risk or a project risk impacting quality management.",
  "regression testing": "A type of change-related testing to detect whether defects have been introduced or uncovered in unchanged areas of the software.",
  "regulatory acceptance testing": "A type of acceptance testing performed to determine the compliance of the test object.",
  "reliability": "The degree to which a component or system performs specified functions under specified conditions for a specified period of time.",
  "requirement": "A provision that contains criteria to be fulfilled.",
  "retrospective": "A regular event in which team members discuss results, review their practices, and identify ways to improve.",
  "review": "A type of static testing in which a work product or process is evaluated by one or more individuals to detect defects or to provide improvements.",
  "reviewer": "A participant in a review who identifies defects in the work product.",
  "risk": "A factor that could result in future negative consequences.",
  "risk analysis": "The overall process of risk identification and risk assessment.",
  "risk assessment": "The process to examine identified risks and determine the risk level.",
  "risk control": "The overall process of risk mitigation and risk monitoring.",
  "risk identification": "The process of finding, recognizing and describing risks.",
  "risk impact": "The damage that will be caused if the risk becomes an actual outcome or event.",
  "risk level": "The measure of a risk defined by risk impact and risk likelihood.",
  "risk likelihood": "The probability that a risk will become an actual outcome or event.",
  "risk management": "The process for handling risks.",
  "risk mitigation": "The process through which decisions are reached and protective measures are implemented for reducing or maintaining risks to specified levels.",
  "risk monitoring": "The activity that checks and reports the status of known risks to stakeholders.",
  "risk-based testing": "Testing in which the management, selection, prioritization, and use of testing activities and resources are based on corresponding risk types and risk levels.",
  "root cause": "A source of a defect such that if it is removed, the occurrence of the defect type is decreased or removed.",
  "root cause analysis": "An analysis technique aimed at identifying the root causes of defects.",
  "scalability": "The degree to which a component or system can be adjusted for changing capacity.",
  "scenario-based review": "A review technique in which a work product is evaluated to determine its ability to address specific scenarios.",
  "scribe": "A person who records information at a review meeting.",
  "security": "The degree to which a component or system protects its data and resources against unauthorized access or use and secures unobstructed access and use for its legitimate users.",
  "sequential development model": "A type of software development lifecycle model in which a complete system is developed in a linear way of several discrete and successive phases with no overlap between them.",
  "service virtualization": "A technique to enable virtual delivery of services which are deployed, accessed and managed remotely.",
  "session-based testing": "A test approach in which test activities are planned as test sessions.",
  "severity": "The degree of impact that a defect has on the development or operation of a component or system.",
  "shift left": "A test approach to perform testing and quality assurance activities as early as possible in the software development lifecycle.",
  "simulator": "A component or system used during testing which behaves or operates like a given component or system.",
  "smoke test": "A test suite that covers the main functionality of a component or system to determine whether it works properly before planned testing begins.",
  "software development lifecycle": "The activities performed at each stage in software development, and how they relate to one another logically and chronologically.",
  "state transition testing": "A black-box test technique in which test cases are designed to exercise elements of a state transition model.",
  "statement coverage": "The coverage of executable statements.",
  "statement testing": "A white-box test technique in which test cases are designed to execute statements.",
  "static analysis": "The process of evaluating a component or system without executing it, based on its form, structure, content, or documentation.",
  "static testing": "Testing that does not involve the execution of a test item.",
  "stub": "A skeletal or special-purpose implementation of a software component, used to develop or test a component that calls or is otherwise dependent on it. It replaces a called component.",
  "system integration testing": "The integration testing of systems.",
  "system testing": "A test level that focuses on verifying that a system as a whole meets specified requirements.",
  "system under test": "A type of test object that is a system.",
  "technical review": "A formal review by technical experts that examine the quality of a work product and identify discrepancies from specifications and standards.",
  "test": "A set of one or more test cases.",
  "test analysis": "The activity that identifies test conditions by analyzing the test basis.",
  "test approach": "The manner of implementing testing tasks.",
  "test automation": "The use of software to perform or support test activities.",
  "test automation framework": "A tool that provides an environment for test automation. It usually includes a test harness and test libraries.",
  "test basis": "The body of knowledge used as the basis for test analysis and design.",
  "test case": "A set of preconditions, inputs, actions (where applicable), expected results and postconditions, developed based on test conditions.",
  "test charter": "Documentation of the goal or objective for a test session.",
  "test completion": "The activity that makes testware available for later use, leaves test environments in a satisfactory condition and communicates the results of testing to relevant stakeholders.",
  "test completion report": "A type of test report produced at completion milestones that provides an evaluation of the corresponding test items against exit criteria.",
  "test condition": "A testable aspect of a component or system identified as a basis for testing.",
  "test control": "The activity that develops and applies corrective actions to get a test project on track when it deviates from what was planned.",
  "test cycle": "An instance of the test process against a single identifiable version of the test object.",
  "test data": "Data needed for test execution.",
  "test design": "The activity that derives and specifies test cases from test conditions.",
  "test environment": "An environment containing hardware, instrumentation, simulators, software tools, and other support elements needed to conduct a test.",
  "test estimation": "An approximation related to various aspects of testing.",
  "test execution": "The activity that runs a test on a component or system producing actual results.",
  "test execution schedule": "A schedule for the execution of test suites within a test cycle.",
  "test harness": "A collection of stubs and drivers needed to execute a test suite",
  "test implementation": "The activity that prepares the testware needed for test execution based on test analysis and design.",
  "test item": "A part of a test object used in the test process.",
  "test level": "A specific instantiation of a test process.",
  "test log": "A chronological record of relevant details about the execution of tests.",
  "test management": "The process of planning, scheduling, estimating, monitoring, reporting, controlling, and completing test activities.",
  "test manager": "The person responsible for project management of testing activities, resources, and evaluation of a test object.",
  "test monitoring": "The activity that checks the status of testing activities, identifies any variances from planned or expected, and reports status to stakeholders.",
  "test object": "The work product to be tested.",
  "test objective": "The purpose for testing.",
  "test plan": "Documentation describing the test objectives to be achieved and the means and the schedule for achieving them, organized to coordinate testing activities.",
  "test planning": "The activity of establishing or updating a test plan.",
  "test policy": "A high-level document describing the principles, approach and major objectives of the organization regarding testing.",
  "test procedure": "A sequence of test cases in execution order, and any associated actions that may be required to set up the initial preconditions and any wrap up activities post execution.",
  "test process": "The set of interrelated activities comprising of test planning, test monitoring and control, test analysis, test design, test implementation, test execution, and test completion.",
  "test progress report": "A type of periodic test report that includes the progress of test activities against a baseline, risks, and alternatives requiring a decision.",
  "test pyramid": "A graphical model representing the relationship of the amount of testing per level, with more at the bottom than at the top.",
  "test report": "Documentation summarizing testing and results.",
  "test reporting": "Collecting and analyzing data from testing activities and subsequently consolidating the data in a report to inform stakeholders.",
  "test result": "The consequence/outcome of the execution of a test.",
  "test run": "The execution of a test suite on a specific version of the test object.",
  "test script": "A sequence of instructions for the execution of a test.",
  "test session": "An uninterrupted period of time spent in executing tests.",
  "test strategy": "A description of how to perform testing to reach test objectives under given circumstances.",
  "test suite": "A set of test scripts or test procedures to be executed in a specific test run.",
  "test technique": "A procedure used to define test conditions, design test cases, and specify test data.",
  "test type": "A group of test activities based on specific test objectives aimed at specific characteristics of a component or system.",
  "test-driven development": "A software development technique in which the test cases are developed, automated and then the software is developed incrementally to pass those test cases.",
  "test-first approach": "An approach to software development in which the test cases are designed and implemented before the associated component or system is developed.",
  "testability": "The degree to which test conditions can be established for a component or system, and tests can be performed to determine whether those test conditions have been met.",
  "tester": "A person who performs testing.",
  "testing": "The process within the software development lifecycle that evaluates the quality of a component or system and related work products.",
  "testing quadrants": "A classification model of test types/test levels in four quadrants, relating them to two dimensions of test objectives: supporting the product team versus critiquing the product, and technology-facing versus business-facing.",
  "testware": "Work products produced during the test process for use in planning, designing, executing, evaluating and reporting on testing.",
  "traceability": "The ability to establish explicit relationships between related work products or items within work products.",
  "unit test framework": "A tool that provides an environment for unit or component testing in which a component can be tested in isolation or with suitable stubs and drivers. It also provides other support for the developer, such as debugging capabilities.",
  "usability": "The degree to which a component or system can be used by specified users to achieve specified goals in a specified context of use.",
  "usability lab": "A test facility in which unintrusive observation of participant reactions and responses to software takes place.",
  "usability testing": "Testing to evaluate the degree to which the system can be used by specified users with effectiveness, efficiency and satisfaction in a specified context of use.",
  "user acceptance testing": "A type of acceptance testing performed to determine if intended users accept the system.",
  "user experience": "A person's perceptions and responses resulting from the use or anticipated use of a software product.",
  "user story": "A user or business requirement consisting of one sentence expressed in the everyday or business language which is capturing the functionality a user needs, the reason behind it, any non-functional criteria, and also including acceptance criteria.",
  "V-model": "A sequential software development lifecycle model describing a one-for-one relationship between major phases of software development from business requirements specification to delivery, and corresponding test levels from acceptance testing to component testing.",
  "validation": "Confirmation by examination that a work product matches a stakeholder's needs.",
  "verification": "Confirmation by examination and through provision of objective evidence that specified requirements have been fulfilled.",
  "walkthrough": "A type of review in which an author leads members of the review through a work product and the members ask questions and make comments about possible issues.",
  "white-box test technique": "A test technique only based on the internal structure of a component or system.",
  "white-box testing": "Testing based on an analysis of the internal structure of the component or system.",
  "Wideband Delphi": "An expert-based test estimation technique that aims at making an accurate estimation using the collective wisdom of the team members."
}
